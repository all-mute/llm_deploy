## Запуск LLM в облаке Yandex Cloud на CPU

Для оптимизации запуска LLM на виртуальных машинах и узлах с CPU существует проект Google [localllm](https://github.com/GoogleCloudPlatform/localllm). В данной инструкции мы расскажем, как развернуть OpenAI Compatible Endpoint в облаке Yandex Cloud с помощью данного инструмента.

Развёртывание проще всего осуществить с помощью Docker-контейнера, в вычислительном узле DataSphere.

> Эта инструкция предполагает, что у вас есть доступ к Yandex Cloud, и вы умеете пользоваться основными облачными инструментами, такими, как `yc`, или веб-интерфейсом облака.

### Подготовка Docker-образа

> Действия ниже можно выполнять на локальном компьютере, или на временной виртуальной машине в облаке.

1. Клонируйте данный репозиторий `git clone http://yandex-datasphere/llm_deploy`
2. Перейдите в папку `localllm`: `cd localllm`
3. Откройте `Dockerfile` и отредактируйте следующую строчку, указав имя модели с HuggingFace, которую вы хотите использовать (в качестве ориентира, хорошо подходят все [квантизированные модели от TheBloke](https://huggingface.co/TheBloke)):
    ```
    ENV MODEL TheBloke/saiga_mistral_7b-GGUF
    ```
3. Соберите Docker-образ с помощью следующей команды:
    ```bash
    docker build --platform linux/amd64 -t localllm .
    ```
    > При сборке обязательно нужно указать параметр --platform, чтобы образ корректно запустился в DataSphere.
4. В результате вы получите Docker-образ, который можно запустить локально:
    ```bash
    docker run -p 8000:8000 localllm
    ```
5. Проверить работоспособность образа вы сможете, выполнив стандартный REST-запрос:
    ```bash
    curl http://127.0.0.1:8000/v1/models
    ```

> В данном Docker-образе осуществляется предзагрузка заданной модели, из-за чего размер образа получается достаточно большим, зато при каждом запуске контейнера не тратится время на скачивание модели с серверов HuggingFace. Если вы не предполагаете часто запускать и останавливать контейнер, то вы можете резко сократить объем Docker-образа, удалив из DockerFile строку `llm pull ${MODEL}`  

### Настройка облачного каталога и сервисного аккаунта

Для разворачивания ноды и хранения Docker-образа вам потребуется некоторый каталог в облаке Yandex Cloud.

> Если у вас не установлен интерфейс командной строки Yandex Cloud, то выполните шаги [в этой инструкции](https://cloud.yandex.ru/ru/docs/cli/quickstart#install).

1. Вы можете создать новый каталог для данного развёртывания, или использовать каталог по умолчанию (Default). Запомните название каталога, оно вам понадобится ниже.
1. Задайте этот каталог каталогом по умолчанию: `yc config set folder-name <название_каталога>`.
1. В каталоге создайте сервисный аккаунт с необходимыми правами доступа - на чтение/запись в Container Registry, на работу с DataSphere.
1. Для сервисного аккаунта создайте json-файл с ключём доступа, он вам потом понадобится:
    ```bash
    yc iam key create --service-account-name <имя_сервисного_аккаунта> \ 
        --output key.json --folder-id <ID_каталога>
    ```

### Помещаем Docker-образ в Container Registry

1. Для хранения Docker-образа создайте в облаке реестр Container Registry, если у вас её пока нет. Скопируйте идентификатор реестра.
    > Идентификатор реестра можно посмотреть, выполнив команду `yc container registry list`
1. Получите IAM-токен для своего пользовательского аккаунта: `yc iam create-token`.
1. Войдите в контейнерный реестр, выполнив команду ниже (подставьте вместо <IAM-токен> значение токена с предыдущего шага):
    ```bash
    docker login \
    --username iam \
    --password <IAM-токен> \
    cr.yandex
    ```
1. Загрузите Docker-образ в Container Registry:
    ```bash
    docker tag localllm cr.yandex/<идентификатор_реестра>/localllm:latest
    docker push cr.yandex/<идентификатор_реестра>/localllm:latest
    ```
> При необходимости можно использовать Docker Hub или другой реестр для хранения образа.

### Создаём ноду DataSphere

1. В настройках проекта DataSphere обязательно укажите каталог по умолчанию и сервисный аккаунт, который вы используете. 
1. В проекте DataSphere создайте новый ресурс "Нода" из Docker-образа. При создании укажите следующие параметры:
    * Имя: <имя_ноды>
    * Тип: Docker-образ
    * Путь к образу: `cr.yandex/<id_container_registry>/localllm:latest`
    * Порт: 8000
    * Таймаут: 180 секунд
    * Для того, чтобы нода могла получить доступ к container registry, в дополнительных параметрах укажите:
        - Имя пользователя: `json_key`
        - Секрет с паролем: создайте секрет в DataSphere, содержащий всё содержимое файла `json.key`, созданного выше.
1. Для тестирования развернутой ноды, можно перейти во вкладку **запрос** и сделать GET-запрос по адресу `/v1/models` - в результате вы получите в ответ список моделей в формате JSON.
1. Вы также можете сделать запрос из интернет, не забывая указывать параметры авторизации облака (IAM-токен), а также идентификатор ноды и облачного каталога:
    ```
    curl -H "x-node-id: <id_ноды>" -H "Authorization: Bearer <IAM_TOKEN>" -H "x-folder-id: <id_каталога>" https://node-api.datasphere.yandexcloud.net/invoke/v1/models
    ```

### Результат

Теперь к развёрнутому сервису можно обращаться через endpoint, совместимый с OpenAI. Единственной существенной особенностью является то, что необходимо для авторизации передавать дополнительные данные (ID ноды, ID каталога и IAM-токен) в заголовке запроса. 

Для балансировки нагрузки между нодами и обновления развернутых сервисов во время работы создайте алиас.
